---
title: "On Locality of Local Explanation Models"
collection: publications
permalink: /publication/on-locality-of-local-explanation-models
excerpt: 'Shapley values provide model agnostic feature attributions for model outcome at a particular instance by simulating feature absence under a global population distribution. The use of a global population can lead to potentially misleading results when local model behaviour is of interest. Hence we consider the formulation of neighbourhood reference distributions that improve the local interpretability of Shapley values. By doing so, we find that the Nadaraya-Watson estimator, a well-studied kernel regressor, can be expressed as a self-normalised importance sampling estimator. Empirically, we observe that Neighbourhood Shapley values identify meaningful sparse feature relevance attributions that provide insight into local model behaviour, complimenting conventional Shapley analysis. They also increase on-manifold explainability and robustness to the construction of adversarial classifiers.
'
date: 2021-07-01
venue: 'arxiv'
paperurl: 'https://arxiv.org/pdf/2106.14648.pdf'
citation: 'SG*, L. Ter-Minassian*, K. DÃ­az-Ordaz, C. Holmes (2021). &quot;On Locality of Local Explanation Models.&quot; <i>pre-print</i>. 1(2).'
---
Shapley values provide model agnostic feature attributions for model outcome at a particular instance by simulating feature absence under a global population distribution. The use of a global population can lead to potentially misleading results when local model behaviour is of interest. Hence we consider the formulation of neighbourhood reference distributions that improve the local interpretability of Shapley values. By doing so, we find that the Nadaraya-Watson estimator, a well-studied kernel regressor, can be expressed as a self-normalised importance sampling estimator. Empirically, we observe that Neighbourhood Shapley values identify meaningful sparse feature relevance attributions that provide insight into local model behaviour, complimenting conventional Shapley analysis. They also increase on-manifold explainability and robustness to the construction of adversarial classifiers.

[Download paper here](https://arxiv.org/pdf/2106.14648.pdf)

Recommended citation: Ghalebikesabi, Sahra, Lucile Ter-Minassian, Karla Diaz-Ordaz, and Chris Holmes. "On Locality of Local Explanation Models." arXiv preprint arXiv:2106.14648 (2021).